{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import import libs, set api keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"It is a priviliage to be study in Peking University\",\n",
    "        \"Math is a very hard subject\"\n",
    "    ], engine=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ApiAttributeError",
     "evalue": "QueryResponse has no attribute 'data' at ['['received_data']']['data']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiAttributeError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-8cb11a728a0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embedding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pinecone/core/client/model_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         raise ApiAttributeError(\n\u001b[0m\u001b[1;32m    503\u001b[0m             \"{0} has no attribute '{1}'\".format(\n\u001b[1;32m    504\u001b[0m                 type(self).__name__, name),\n",
      "\u001b[0;31mApiAttributeError\u001b[0m: QueryResponse has no attribute 'data' at ['['received_data']']['data']"
     ]
    }
   ],
   "source": [
    "len(res['data'][0]['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-6783132eb6e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embedding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "res.keys()\n",
    "res['data'][0]['embedding']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we iniate the vector database via Pinecone API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "index_name = 'notion-database'\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],\n",
    "    environment=\"us-east1-gcp\"\n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        # creates an idex of dimension 1536\n",
    "        metric='cosine',\n",
    "        # metric='euclidean',\n",
    "        metadata_config={'indexed': ['channel_id', 'published']}\n",
    "    )\n",
    "# connect to index\n",
    "index = pinecone.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()\n",
    "\n",
    "# an error was met and solved upon retring && upgrading jupyter notebook with `pip install notebook --upgrade`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data/Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is the logic for ingesting Notion data into LangChain.\"\"\"\n",
    "from pathlib import Path\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# import faiss\n",
    "# from langchain.vectorstores import FAISS\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "# import pickle\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Here we load in the data in the format that Notion exports it in.\n",
    "ps = list(Path(\"Notion_DB/\").glob(\"**/*.md\"))\n",
    "\n",
    "data = []\n",
    "sources = []\n",
    "for p in ps:\n",
    "    with open(p) as f:\n",
    "        data.append(f.read())\n",
    "    sources.append(p)\n",
    "\n",
    "\n",
    "# here the content of each .md file is stored as an element in the list `data`, which is very huge\n",
    "# and the path of each .md file is stored as an element in the list `sources`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next we split the documents, as needed, into smaller chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "# We do this due to the context limits of the LLMs.\n",
    "\n",
    "# chunk size is 1000, which means each chunk of text will be 1000 characters long, and that the separator is a new line\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, separator=\"\\n\")\n",
    "docs = []\n",
    "metadatas = []\n",
    "for i, d in enumerate(data):\n",
    "    # where i, d is the index and content of each .md file respectively\n",
    "    splits = text_splitter.split_text(d)\n",
    "    docs.extend(splits)\n",
    "    metadatas.extend([{\"source\": sources[i]}] * len(splits))\n",
    "print(len(docs))\n",
    "\n",
    "# question, will the data be too big/unspecific for each chunk?\n",
    "# now len(docs) should be the number of vectors this is going to create"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we vectorize the docs using the embedding model and then upload them into Pinecone\n",
    "\n",
    "it seems to me that we don't really need such a vector database so powerful as Pinecone, any vector database should suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 214/214 [08:25<00:00,  2.36s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import datetime\n",
    "from time import sleep\n",
    "\n",
    "# batch_size = 100  # how many embeddings we create and insert at once\n",
    "vector_lists = []\n",
    "id_batch = [x for x in range(0, len(docs))]\n",
    "for i in tqdm(range(0, len(docs))):\n",
    "    # get texts to encode\n",
    "    texts = docs[i]\n",
    "    # create embeddings (try-except added to avoid RateLimitError)\n",
    "    res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "    \n",
    "    # try:\n",
    "    #     res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "    # except:\n",
    "    #     done = False\n",
    "    #     while not done:\n",
    "    #         sleep(5)\n",
    "    #         try:\n",
    "    #             res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "    #             done = True\n",
    "    #         except:\n",
    "    #             pass\n",
    "    embed = [res['data'][0]['embedding']] # the coordinates of the vector, in semantic or embedding space.\n",
    "    \n",
    "    vector = list(zip(id_batch, embed))\n",
    "    # no metadata is added in this version\n",
    "    vector_lists.append(vector)\n",
    "# print(vector_lists) # use this line with caution, its VERY long (dim * number of vector, a list of 153,600 elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.upsert([\n",
    "#     (\"A\", [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]),\n",
    "#     (\"B\", [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]),\n",
    "#     (\"C\", [0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3]),\n",
    "#     (\"D\", [0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4]),\n",
    "#     (\"E\", [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5])\n",
    "# ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay we forgot to upload the vectors to Pinecone lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid vector value passed: cannot interpret type <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-26a335599866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# index.upsert(vector_lists)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pinecone/core/utils/error_handling.py\u001b[0m in \u001b[0;36minner_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# raises exceptions in case of invalid config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProtocolError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pinecone/index.py\u001b[0m in \u001b[0;36mupsert\u001b[0;34m(self, vectors, namespace, batch_size, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upsert_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pinecone/index.py\u001b[0m in \u001b[0;36m_upsert_batch\u001b[0;34m(self, vectors, namespace, _check_type, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         return self._vector_api.upsert(\n\u001b[1;32m    232\u001b[0m             UpsertRequest(\n\u001b[0;32m--> 233\u001b[0;31m                 \u001b[0mvectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_vector_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0margs_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0m_check_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pinecone/index.py\u001b[0m in \u001b[0;36m_vector_transform\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_dict_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid vector value passed: cannot interpret type {type(item)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         return self._vector_api.upsert(\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid vector value passed: cannot interpret type <class 'int'>"
     ]
    }
   ],
   "source": [
    "# len(vector_lists[200][0][1])\n",
    "# vector_lists[200][0][1]\n",
    "# vector_lists[200][0][1]\n",
    "\n",
    "# index.upsert(vector_lists)\n",
    "for i in range(len(vector_lists)):\n",
    "    index.upsert((i, vector_lists[i][0][1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And Now, We CAN FINALLY QUERY THE DATABASE!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is attachment style?\"\n",
    "\n",
    "query_emb = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "query_coord = query_emb['data'][0]['embedding']\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "query_res = index.query(query_coord, top_k=10, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [], 'namespace': ''}\n"
     ]
    }
   ],
   "source": [
    "print(query_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
